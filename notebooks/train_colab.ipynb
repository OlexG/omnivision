{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Drone Detection Model on Google Colab (FREE GPU)\n",
    "\n",
    "**Setup Instructions:**\n",
    "1. Upload this notebook to Google Colab\n",
    "2. Go to Runtime → Change runtime type → Select **T4 GPU**\n",
    "3. Run all cells\n",
    "\n",
    "Training time: ~5-10 minutes on GPU (vs hours on Mac CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics roboflow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Dataset from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# Initialize Roboflow with your API key\n",
    "API_KEY = \"aO6VaU58uJ4WMpjdwVWU\"  # Replace with your key if different\n",
    "rf = Roboflow(api_key=API_KEY)\n",
    "\n",
    "# Download drone-vs-bird dataset\n",
    "project = rf.workspace(\"oleksandr-gorpynich\").project(\"drone-vs-bird-object-detection-2fnnk\")\n",
    "dataset = project.version(1).download(\"yolov8\")\n",
    "\n",
    "print(f\"Dataset downloaded to: {dataset.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert to Binary Dataset (drone vs not-drone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def create_binary_dataset(dataset_path, output_path=\"drone_binary\"):\n",
    "    dataset_path = Path(dataset_path)\n",
    "    output_path = Path(output_path)\n",
    "    \n",
    "    # Read data.yaml\n",
    "    with open(dataset_path / \"data.yaml\", 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    class_names = data_config['names']\n",
    "    drone_idx = class_names.index('drone')\n",
    "    \n",
    "    print(f\"Original classes: {class_names}\")\n",
    "    print(f\"Converting to binary: drone (0) vs not-drone (1)\")\n",
    "    \n",
    "    # Process each split\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        split_path = dataset_path / split\n",
    "        if not split_path.exists():\n",
    "            continue\n",
    "        \n",
    "        out_images = output_path / split / \"images\"\n",
    "        out_labels = output_path / split / \"labels\"\n",
    "        out_images.mkdir(parents=True, exist_ok=True)\n",
    "        out_labels.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        images_path = split_path / \"images\"\n",
    "        labels_path = split_path / \"labels\"\n",
    "        \n",
    "        count = 0\n",
    "        for label_file in labels_path.glob(\"*.txt\"):\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            # Relabel: drone=0, everything else=1\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    continue\n",
    "                class_id = int(parts[0])\n",
    "                parts[0] = '0' if class_id == drone_idx else '1'\n",
    "                new_lines.append(' '.join(parts) + '\\n')\n",
    "            \n",
    "            # Copy image\n",
    "            image_name = label_file.stem\n",
    "            for ext in ['.jpg', '.jpeg', '.png']:\n",
    "                image_file = images_path / f\"{image_name}{ext}\"\n",
    "                if image_file.exists():\n",
    "                    shutil.copy2(image_file, out_images / f\"{image_name}{ext}\")\n",
    "                    break\n",
    "            \n",
    "            # Write relabeled annotations\n",
    "            with open(out_labels / label_file.name, 'w') as f:\n",
    "                f.writelines(new_lines)\n",
    "            count += 1\n",
    "        \n",
    "        print(f\"{split}: {count} images\")\n",
    "    \n",
    "    # Create new data.yaml\n",
    "    new_data_config = {\n",
    "        'path': str(output_path.absolute()),\n",
    "        'train': 'train/images',\n",
    "        'val': 'valid/images',\n",
    "        'test': 'test/images',\n",
    "        'names': {0: 'drone', 1: 'not-drone'},\n",
    "        'nc': 2\n",
    "    }\n",
    "    \n",
    "    with open(output_path / \"data.yaml\", 'w') as f:\n",
    "        yaml.dump(new_data_config, f)\n",
    "    \n",
    "    print(f\"\\n✓ Binary dataset created at: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Convert dataset\n",
    "binary_dataset = create_binary_dataset(dataset.location)\n",
    "data_yaml = binary_dataset / \"data.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train YOLOv8 Model (Fast on GPU!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train\n",
    "results = model.train(\n",
    "    data=str(data_yaml),\n",
    "    epochs=25,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='drone_detection',\n",
    "    device=0  # Use GPU\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "metrics = model.val()\n",
    "\n",
    "print(f\"mAP50: {metrics.box.map50:.3f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.3f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.3f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Get test images\n",
    "test_images = list(Path(binary_dataset / \"test/images\").glob(\"*.jpg\"))[:6]\n",
    "\n",
    "# Run inference\n",
    "results = model.predict(test_images, conf=0.25)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (result, ax) in enumerate(zip(results, axes)):\n",
    "    img = result.plot()\n",
    "    img = img[:, :, ::-1]  # BGR to RGB\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"{len(result.boxes)} detection(s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "best_model = \"runs/detect/drone_detection/weights/best.pt\"\n",
    "\n",
    "if os.path.exists(best_model):\n",
    "    print(\"Downloading trained model...\")\n",
    "    files.download(best_model)\n",
    "    print(\"✓ Download complete! Upload this to your Mac.\")\n",
    "else:\n",
    "    print(f\"Model not found at {best_model}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
